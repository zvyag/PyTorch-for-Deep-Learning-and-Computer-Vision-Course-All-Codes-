{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zvyag/PyTorch-for-Deep-Learning-and-Computer-Vision-Course-All-Codes-/blob/master/pytorch_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHgshdnD_tD-",
        "colab_type": "code",
        "outputId": "1f74fddf-8179-43e3-9948-2d737d71b9fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcdyJEoh_7ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-2Qre0hr8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skLmIgFasS6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc27727d-c0e8-475a-dd98-e1a35457f6ae"
      },
      "source": [
        "!git clone https://github.com/jaddoescad/ants_and_bees.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ants_and_bees' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybkhbs4tskmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9546505-424a-466a-b5cd-1934be7fb059"
      },
      "source": [
        "!ls ants_and_bees/train/ants"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0013035.jpg\t\t     408393566_b5b694119b.jpg\n",
            " 1030023514_aad5c608f9.jpg   424119020_6d57481dab.jpg\n",
            " 1095476100_3906d8afde.jpg   424873399_47658a91fb.jpg\n",
            " 1099452230_d1949d3250.jpg   450057712_771b3bfc91.jpg\n",
            " 116570827_e9c126745d.jpg    45472593_bfd624f8dc.jpg\n",
            " 1225872729_6f0856588f.jpg   459694881_ac657d3187.jpg\n",
            " 1262877379_64fcada201.jpg   460372577_f2f6a8c9fc.jpg\n",
            " 1269756697_0bce92cdab.jpg   460874319_0a45ab4d05.jpg\n",
            " 1286984635_5119e80de1.jpg   466430434_4000737de9.jpg\n",
            " 132478121_2a430adea2.jpg    470127037_513711fd21.jpg\n",
            " 1360291657_dc248c5eea.jpg   474806473_ca6caab245.jpg\n",
            " 1368913450_e146e2fb6d.jpg   475961153_b8c13fd405.jpg\n",
            " 1473187633_63ccaacea6.jpg   484293231_e53cfc0c89.jpg\n",
            " 148715752_302c84f5a4.jpg    49375974_e28ba6f17e.jpg\n",
            " 1489674356_09d48dde0a.jpg   506249802_207cd979b4.jpg\n",
            " 149244013_c529578289.jpg    506249836_717b73f540.jpg\n",
            " 150801003_3390b73135.jpg    512164029_c0a66b8498.jpg\n",
            " 150801171_cd86f17ed8.jpg    512863248_43c8ce579b.jpg\n",
            " 154124431_65460430f2.jpg    518773929_734dbc5ff4.jpg\n",
            " 162603798_40b51f1654.jpg    522163566_fec115ca66.jpg\n",
            " 1660097129_384bf54490.jpg   522415432_2218f34bf8.jpg\n",
            " 167890289_dd5ba923f3.jpg    531979952_bde12b3bc0.jpg\n",
            " 1693954099_46d4c20605.jpg   533848102_70a85ad6dd.jpg\n",
            " 175998972.jpg\t\t     535522953_308353a07c.jpg\n",
            " 178538489_bec7649292.jpg    540889389_48bb588b21.jpg\n",
            " 1804095607_0341701e1c.jpg   541630764_dbd285d63c.jpg\n",
            " 1808777855_2a895621d7.jpg   543417860_b14237f569.jpg\n",
            " 188552436_605cc9b36b.jpg    560966032_988f4d7bc4.jpg\n",
            " 1917341202_d00a7f9af5.jpg   5650366_e22b7e1065.jpg\n",
            " 1924473702_daa9aacdbe.jpg   6240329_72c01e663e.jpg\n",
            " 196057951_63bf063b92.jpg    6240338_93729615ec.jpg\n",
            " 196757565_326437f5fe.jpg    649026570_e58656104b.jpg\n",
            " 201558278_fe4caecc76.jpg    662541407_ff8db781e7.jpg\n",
            " 201790779_527f4c0168.jpg    67270775_e9fdf77e9d.jpg\n",
            " 2019439677_2db655d361.jpg   6743948_2b8c096dda.jpg\n",
            " 207947948_3ab29d7207.jpg    684133190_35b62c0c1d.jpg\n",
            " 20935278_9190345f6b.jpg     69639610_95e0de17aa.jpg\n",
            " 224655713_3956f7d39a.jpg    707895295_009cf23188.jpg\n",
            " 2265824718_2c96f485da.jpg   7759525_1363d24e88.jpg\n",
            " 2265825502_fff99cfd2d.jpg   795000156_a9900a4a71.jpg\n",
            " 226951206_d6bf946504.jpg    822537660_caf4ba5514.jpg\n",
            " 2278278459_6b99605e50.jpg   82852639_52b7f7f5e3.jpg\n",
            " 2288450226_a6e96e8fdf.jpg   841049277_b28e58ad05.jpg\n",
            " 2288481644_83ff7e4572.jpg   886401651_f878e888cd.jpg\n",
            " 2292213964_ca51ce4bef.jpg   892108839_f1aad4ca46.jpg\n",
            " 24335309_c5ea483bb8.jpg     938946700_ca1c669085.jpg\n",
            " 245647475_9523dfd13e.jpg    957233405_25c1d1187b.jpg\n",
            " 255434217_1b2b3fe0a4.jpg    9715481_b3cb4114ff.jpg\n",
            " 258217966_d9d90d18d3.jpg    998118368_6ac1d91f81.jpg\n",
            " 275429470_b2d7d9290b.jpg    Ant_1.jpg\n",
            " 28847243_e79fe052cd.jpg    'ant photos.jpg'\n",
            " 318052216_84dff3f98a.jpg    army-ants-red-picture.jpg\n",
            " 334167043_cbd1adaeb9.jpg    formica.jpeg\n",
            " 339670531_94b75ae47a.jpg    hormiga_co_por.jpg\n",
            " 342438950_a3da61deab.jpg    imageNotFound.gif\n",
            " 36439863_0bec9f554f.jpg     kurokusa.jpg\n",
            " 374435068_7eee412ec4.jpg    MehdiabadiAnt2_600.jpg\n",
            " 382971067_0bfd33afe0.jpg    Nepenthes_rafflesiana_ant.jpg\n",
            " 384191229_5779cf591b.jpg    swiss-army-ant.jpg\n",
            " 386190770_672743c9a7.jpg    termite-vs-ant.jpg\n",
            " 392382602_1b7bed32fa.jpg    trap-jaw-ant-insect-bg.jpg\n",
            " 403746349_71384f5b58.jpg    VietnameseAntMimicSpider.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uubY91y6AcSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomRotation(10),\n",
        "                                transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "                                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                               ])\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                               ])\n",
        "training_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "validation_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=100, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1p7rbHZB6Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def im_convert(tensor):\n",
        "  image = tensor.clone().detach().numpy()\n",
        "  image = image.transpose(1, 2, 0)  # change the shape (1, 28, 28) -> (28, 28, 1)\n",
        "  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
        "  image = image.clip(0, 1)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgO-4E8Kt1tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TwccPcxDbpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "\n",
        "for idx in np.arange(20):\n",
        "  ax = fig.add_subplot(2, 10, idx+1)\n",
        "  plt.imshow(im_convert(images[idx]))\n",
        "  ax.set_title(classes[labels[idx].item()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwNmxw6bDdLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  \n",
        "  def __init__(self, D_in, H1, H2, D_out):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(D_in, H1)\n",
        "    self.linear2 = nn.Linear(H1, H2)\n",
        "    self.linear3 = nn.Linear(H2, D_out)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = F.relu(self.linear2(x))\n",
        "    x = self.linear3(x)  # no activation function here, the output is not binary!\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au5nfkwevZJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # here we only define the layers, the network whith subsequent application of layers is described within the forward function\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1)  # in_channels, out_channels, kernel_size, stride)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
        "    self.fc1 = nn.Linear(4*4*64, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "    self.dropout1 = nn.Dropout(0.5)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2, 2)  # reducing image size in half\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 4*4*64)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout1(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AqSDKXWaI7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LeNet().to(device)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOUNvGU0acgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()  # used for multiclass classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IISdo82BtbFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(inputs, labels):\n",
        "  outputs = model(inputs)  \n",
        "  return criterion(outputs, labels), outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxTLX9AAbSVp",
        "colab_type": "code",
        "outputId": "2daee9ec-08f5-473a-970b-88480cbe065a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "epochs = 12\n",
        "running_loss_history = []\n",
        "running_corrects_history = []\n",
        "val_running_loss_history = []\n",
        "val_running_corrects_history = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "  val_running_loss = 0.0\n",
        "  val_running_corrects = 0.0\n",
        "  \n",
        "  for train_in, train_label in training_loader:\n",
        "    train_in = train_in.to(device)\n",
        "    train_label = train_label.to(device)\n",
        "    loss, out = compute_loss(train_in, train_label)  # loss computed on one batch\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    _, preds = torch.max(out, 1)    \n",
        "    running_loss += loss.item()\n",
        "    running_corrects += torch.sum(preds == train_label.data)  # number of correct predictions in each batch\n",
        "  else:\n",
        "    with torch.no_grad():  # to save memory\n",
        "      for val_in, val_labels in validation_loader:\n",
        "        val_in = val_in.to(device)\n",
        "        val_labels = val_labels.to(device)\n",
        "        val_loss, val_out = compute_loss(val_in, val_labels)\n",
        "        \n",
        "        _, val_preds = torch.max(val_out, 1)    \n",
        "        val_running_loss += val_loss.item()\n",
        "        val_running_corrects += torch.sum(val_preds == val_labels.data)  # number of correct predictions in each batch\n",
        "      \n",
        "    epoch_loss = running_loss / len(training_loader)\n",
        "    epoch_acc = running_corrects.float() / len(training_loader)\n",
        "    running_loss_history.append(epoch_loss)\n",
        "    running_corrects_history.append(epoch_acc)\n",
        "    \n",
        "    val_epoch_loss = val_running_loss / len(validation_loader)\n",
        "    val_epoch_acc = val_running_corrects.float() / len(validation_loader)\n",
        "    val_running_loss_history.append(val_epoch_loss)\n",
        "    val_running_corrects_history.append(val_epoch_acc)\n",
        "    \n",
        "    print(\"epoch: \", i)\n",
        "    print(\"training loss: {:.4f}, acc: {:.4f}\".format(epoch_loss, epoch_acc.item()))\n",
        "    print(\"validation loss: {:.4f}, val acc: {:.4f}\".format(val_epoch_loss, val_epoch_acc.item()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-72655e7ff212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mval_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-319fb4fcb1fa>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(inputs, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 942\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1867\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1869\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (4900) to match target batch_size (100)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJo1k036gEXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(running_loss_history, label=\"training loss\")\n",
        "plt.plot(val_running_loss_history, label=\"validation loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXX__dSImeJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(running_corrects_history, label=\"training acc\")\n",
        "plt.plot(val_running_corrects_history, label=\"validation acc\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-pqaQxRp9np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}